# ğŸ¦„ Pegazus Event Extraction

Pipeline complet pour l'extraction dâ€™Ã©vÃ©nements Ã  partir de descriptions textuelles, avec gÃ©nÃ©ration de triplets relationnels Ã  partir de phrases.

---

## ğŸ” Pipeline dâ€™extraction dâ€™Ã©vÃ©nements

### 1. ğŸ¯ EntrÃ©e
- **Fichier CSV** contenant des phrases dÃ©crivant des Ã©vÃ©nements Ã  extraire.
- Extrait typique :
```
event,event_label,time,line_id,landmark_label,landmark_type,relatum_label,relatum_type,relation_type,change_type,change_on,attribute_type,outdates,makes_effective
96,rue eugÃ¨ne oudinÃ© || Historique || PrÃ©cÃ©demment, rue Watt prolongÃ©e,,10605_historique,Rue EugÃ¨ne OudinÃ©,rue,,,,transition,attribute,name,rue Watt prolongÃ©e,rue de Rigny
```

---

### 2. ğŸ› ï¸ Conversion vers JSON

Deux cas selon la mÃ©thode utilisÃ©e :

#### Pour **LLM** :
Format JSON avec une phrase associÃ©e Ã  une liste de triplets :
```json
{
  "sentence" : "Ceci est un Ã©vÃ©nement dÃ©crivant une Ã©volution territoriale",
  "triples": [
    ["sub1", "rel1", "obj1"],
    ["sub2", "rel2", "obj2"]
  ]
}
```

#### Pour **BERT** :
Format JSON indiquant les entitÃ©s et les relations :
```json
{
  "sentence": "Le texte de la phrase",
  "entities": [...],
  "relations": [...]
}
```

ğŸ‘‰ Voir [ground_truth_conversion.md](doc/ground_truth_conversion.md) pour plus de dÃ©tails sur la conversion.

---

### 3. ğŸ“‚ RÃ©partition des donnÃ©es

Les donnÃ©es convertÃ©es sont rÃ©parties en trois ensembles :
- **EntraÃ®nement**
- **Validation**
- **Test**

---

## ğŸ”€ Pipelines par mÃ©thode

### ğŸ§  MÃ©thode LLM
1. **CrÃ©ation du prompt** : prÃ©paration du prompt + ajout des exemples d'entraÃ®nement.
2. **InfÃ©rence** sur le jeu de test.
3. **RÃ©sultats** : sortie au format JSON (liste de triplets par phrase).

### ğŸ¤– MÃ©thode BERT
1. **Fine-tuning** sur le jeu d'entraÃ®nement.
2. **InfÃ©rence** sur le jeu de test.
3. **RÃ©sultats** : sortie au format entitÃ©s + relations.

---

### âœ… Ã‰valuation

- Adaptation des rÃ©sultats BERT vers le **format triplet** (identique Ã  LLM).
- Comparaison des deux mÃ©thodes.
- **BERT** est utilisÃ© comme **baseline** pour lâ€™Ã©valuation.
- Production de **scores dâ€™Ã©valuation** (prÃ©cision, rappel, F1, etc.).

---

## ğŸ—ºï¸ SchÃ©ma (ASCII)

```
[CSV input]
     |
     v
[Conversion JSON]
     |
     v
[Split train / val / test]
     |
     +------------------------------+
     |                              |
     v                              v
[LLM pipeline]               [BERT pipeline]
  Prompt + exemples            Fine-tuning
        |                           |
        v                           v
[LLM infÃ©rence]              [BERT infÃ©rence]
        |                           |
        +------------+--------------+
                     |
                     v
             [Adaptation des formats]
                     |
                     v
             [Ã‰valuation & scores]
```

---

## ğŸ“ Structure du dÃ©pÃ´t

- `data/` : fichiers CSV et JSON de travail
- `utils/` : scripts utilitaires (prÃ©traitement, conversion, etc.)
- `doc/` : documentation dÃ©taillÃ©e

---

## Utilisation

### Conversion de la vÃ©ritÃ© terrain (ground truth) vers JSON

Pour gÃ©nÃ©rer les fichiers JSONL Ã  partir de `ground_truth.csv`, il faut exÃ©cuter le script `prepare_dataset.py`.

Cela produit trois fichiers de descriptions d'Ã©vÃ©nements :

- `complex_ground_truth.jsonl` â€” une version **complexe** de la vÃ©ritÃ© terrain  
- `simple_ground_truth.jsonl` â€” une version **simple** de la vÃ©ritÃ© terrain
- `bert_simple_ground_truth.jsonl` â€” une version **simple** de la vÃ©ritÃ© terrain pour BERT

La **deuxiÃ¨me version "simple enrichie"** est ensuite automatiquement gÃ©nÃ©rÃ©e Ã  partir du fichier simple :

- Les dates au format ISO (`YYYY`, `YYYY-MM`, `YYYY-MM-DD`) sont converties en **langage naturel franÃ§ais**  
  _Exemples :_  
  `1909-01-03` â†’ `3 janvier 1909`  
  `2023-09` â†’ `septembre 2023`

- Certains triplets sont **modifiÃ©s** ou **supprimÃ©s** :
  - Les triplets avec `rel: "isLandmarkType"` sont transformÃ©s en inversant `sub` et `obj`, et `rel` devient `isLandmarkTypeOf`
  - Les triplets avec `rel: "hasTime"` et `obj: "noTime"` sont supprimÃ©s
  - Les triplets avec `rel: "hasNewName"` ou `"hasOldName"` dont le sujet est identique Ã  l'objet (sans tenir compte de la casse) sont supprimÃ©s

Chaque fichier JSONL est ensuite automatiquement **divisÃ©** en trois sous-ensembles :

- `*_train.jsonl` â€” pour l'**entraÃ®nement**
- `*_val.jsonl` â€” pour la **validation**
- `*_test.jsonl` â€” pour les **tests**

Les fichiers divisÃ©s sont enregistrÃ©s dans le dossier `data`.

> **Remarque :** Assurez-vous que le fichier `ground_truth.csv` est bien prÃ©sent dans le rÃ©pertoire attendu avant dâ€™exÃ©cuter le script.

---

#### ğŸ“Š SchÃ©ma du pipeline de prÃ©paration des donnÃ©es

| Ã‰tape | EntrÃ©e                    | Traitement                                                                 | Sorties                                                    |
|-------|---------------------------|----------------------------------------------------------------------------|-------------------------------------------------------------|
| 1ï¸âƒ£    | `ground_truth.csv`        | GÃ©nÃ©ration des descriptions d'Ã©vÃ©nements (simple et complexe)              | `complex_ground_truth.jsonl`<br>`simple_ground_truth.jsonl`<br>`bert_simple_ground_truth.jsonl`|
| 2ï¸âƒ£    | Fichiers JSONL            | DÃ©coupage en train / val / test                                           | Fichiers `*_train.jsonl`, `*_val.jsonl`, `*_test.jsonl` dans `data/` |

---

## ğŸ“Œ TODO

- [ ] Ajouter pipeline de post-traitement pour les erreurs LLM
- [ ] Ajouter visualisation interactive des triplets extraits
- [ ] Publier benchmark complet sur diffÃ©rents modÃ¨les
