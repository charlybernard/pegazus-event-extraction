# ğŸ¦„ Pegazus Event Extraction

Pipeline complet pour l'extraction d'Ã©vÃ©nements Ã  partir de descriptions textuelles, avec gÃ©nÃ©ration de triplets relationnels Ã  partir de phrases.

---

## ğŸ” Pipeline dâ€™extraction dâ€™Ã©vÃ©nements

### 1. ğŸ¯ EntrÃ©e
- **Fichier CSV** contenant des phrases dÃ©crivant des Ã©vÃ©nements Ã  extraire.
- Extrait typique :
```
event,event_label,time,line_id,landmark_label,landmark_type,relatum_label,relatum_type,relation_type,change_type,change_on,attribute_type,outdates,makes_effective
96,rue eugÃ¨ne oudinÃ© || Historique || PrÃ©cÃ©demment, rue Watt prolongÃ©e,,10605_historique,Rue EugÃ¨ne OudinÃ©,rue,,,,transition,attribute,name,rue Watt prolongÃ©e,rue de Rigny
```

---

### 2. ğŸ› ï¸ Conversion vers JSON

Deux cas selon la mÃ©thode utilisÃ©e :

#### Pour **LLM** :
Format JSON avec une phrase associÃ©e Ã  une liste de triplets :
```json
{
  "sentence" : "Ceci est un Ã©vÃ©nement dÃ©crivant une Ã©volution territoriale",
  "triples": [
    ["sub1", "rel1", "obj1"],
    ["sub2", "rel2", "obj2"]
  ]
}
```

#### Pour **BERT** :
Format JSON indiquant les entitÃ©s et les relations :
```json
{
  "sentence": "Le texte de la phrase",
  "entities": [...],
  "relations": [...]
}
```

#### Utilisation

##### Conversion de la vÃ©ritÃ© terrain (ground truth) vers JSON

Pour gÃ©nÃ©rer les fichiers JSONL Ã  partir de `ground_truth.csv`, il faut exÃ©cuter le script `main.py`.

Cela produira deux fichiers :

- `complex_ground_truth.jsonl` â€” une version **complexe** de la vÃ©ritÃ© terrain
- `simple_ground_truth.jsonl` â€” une version **simple** de la vÃ©ritÃ© terrain

Assurez-vous que le fichier `ground_truth.csv` est bien prÃ©sent dans le rÃ©pertoire attendu avant dâ€™exÃ©cuter le script.

ğŸ‘‰ Voir [ground_truth_conversion.md](doc/ground_truth_conversion.md) pour plus de dÃ©tails sur la conversion.

---

### 3. ğŸ“‚ RÃ©partition des donnÃ©es

Les donnÃ©es converties sont rÃ©parties en trois ensembles :
- **EntraÃ®nement**
- **Validation**
- **Test**

---

## ğŸ”€ Pipelines par mÃ©thode

### ğŸ§  MÃ©thode LLM
1. **CrÃ©ation du prompt** : prÃ©paration du prompt + ajout des exemples d'entraÃ®nement.
2. **InfÃ©rence** sur le jeu de test.
3. **RÃ©sultats** : sortie au format JSON (liste de triplets par phrase).

### ğŸ¤– MÃ©thode BERT
1. **Fine-tuning** sur le jeu d'entraÃ®nement.
2. **InfÃ©rence** sur le jeu de test.
3. **RÃ©sultats** : sortie au format entitÃ©s + relations.

---

### âœ… Ã‰valuation

- Adaptation des rÃ©sultats BERT vers le **format triplet** (identique Ã  LLM).
- Comparaison des deux mÃ©thodes.
- **BERT** est utilisÃ© comme **baseline** pour lâ€™Ã©valuation.
- Production de **scores dâ€™Ã©valuation** (prÃ©cision, rappel, F1, etc.).

---

## ğŸ—ºï¸ SchÃ©ma (ASCII)

```
[CSV input]
     |
     v
[Conversion JSON]
     |
     v
[Split train / val / test]
     |
     +------------------------------+
     |                              |
     v                              v
[LLM pipeline]               [BERT pipeline]
  Prompt + exemples            Fine-tuning
        |                           |
        v                           v
[LLM infÃ©rence]              [BERT infÃ©rence]
        |                           |
        +------------+--------------+
                     |
                     v
             [Adaptation des formats]
                     |
                     v
             [Ã‰valuation & scores]
```

---

## ğŸ“ Structure du dÃ©pÃ´t

- `data/` : fichiers CSV et JSON de travail
- `llm/` : gestion des prompts et infÃ©rence LLM
- `bert/` : entraÃ®nement et infÃ©rence avec BERT
- `utils/` : scripts utilitaires (prÃ©traitement, conversion, etc.)
- `doc/` : documentation dÃ©taillÃ©e

---

## ğŸ“Œ TODO

- [ ] Ajouter pipeline de post-traitement pour les erreurs LLM
- [ ] Ajouter visualisation interactive des triplets extraits
- [ ] Publier benchmark complet sur diffÃ©rents modÃ¨les

---
